This project "Communication Through Gestures" is an implementation of a CNN model trained to recognize 4 gestures, namely 'Hi', 'One', 'Super', and 'V' or 'Victory'.
The CNN model has been trained to extract 128 features and for 10 epochs.
The Project.ipynb file is a Jupyter Notebook file that contains the code for the CNN model.
The gesture_recognition.py file is a Spyder Notebook file that contains the code for the project.
The repository also contains the Project Report for further details.
I'd appreciate any suggestions / improvements from anyone. Also, feel free to contact me in case of any doubts.

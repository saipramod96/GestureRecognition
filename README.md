This project is titled "Communication Through Gestures", and runs on the Keras Framework. It is a CNN model trained to recognize 4 gestures, namely 'Hi', 'One', 'Super', and 'V' or 'Victory'.
The CNN model has been trained to extract 128 features and for 10 epochs.
The Project.ipynb file is a Jupyter Notebook file that contains the code for the CNN model.
The gesture_recognition.py file is a Spyder Notebook file that contains the UI for the project.
The repository also contains the Project Report for further details and clarifications. 
I'd appreciate any suggestions / improvements from anyone. Also, feel free to contact me in case of any doubts.
